\BOOKMARK [1][-]{section.1}{Abstract}{}% 1
\BOOKMARK [1][-]{section.2}{Intorduction to Neural networks}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Perceptrons}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Multi layer peceptrons}{section.2}% 4
\BOOKMARK [2][-]{subsection.2.3}{Gradient decent}{section.2}% 5
\BOOKMARK [2][-]{subsection.2.4}{Activation functions}{section.2}% 6
\BOOKMARK [2][-]{subsection.2.5}{Feed forward}{section.2}% 7
\BOOKMARK [2][-]{subsection.2.6}{Error functions}{section.2}% 8
\BOOKMARK [2][-]{subsection.2.7}{Back propigation}{section.2}% 9
\BOOKMARK [1][-]{section.3}{Intorduction to Recurrant Neural Networks}{}% 10
\BOOKMARK [2][-]{subsection.3.1}{RNN concepts}{section.3}% 11
\BOOKMARK [2][-]{subsection.3.2}{LSTM}{section.3}% 12
\BOOKMARK [1][-]{section.4}{Noize net}{}% 13
\BOOKMARK [2][-]{subsection.4.1}{Data and preprocessing}{section.4}% 14
\BOOKMARK [2][-]{subsection.4.2}{Architecture}{section.4}% 15
\BOOKMARK [2][-]{subsection.4.3}{Implimentation}{section.4}% 16
\BOOKMARK [2][-]{subsection.4.4}{Results}{section.4}% 17
\BOOKMARK [2][-]{subsection.4.5}{Conclusion}{section.4}% 18
